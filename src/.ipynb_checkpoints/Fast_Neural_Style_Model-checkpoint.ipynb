{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get COCO dataset. Only run once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "XY0QCo4X6AX7",
    "outputId": "478d6103-02ea-4237-df75-6176eff5250a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-04-25 22:05:50--  http://images.cocodataset.org/zips/test2015.zip\n",
      "Resolving images.cocodataset.org (images.cocodataset.org)... 52.216.177.211\n",
      "Connecting to images.cocodataset.org (images.cocodataset.org)|52.216.177.211|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13270587935 (12G) [application/zip]\n",
      "Saving to: ‘test2015.zip.1’\n",
      "\n",
      "test2015.zip.1        0%[                    ]  96.13M  44.7MB/s               ^C\n"
     ]
    }
   ],
   "source": [
    "!wget http://images.cocodataset.org/zips/test2015.zip\n",
    "! unzip test2015.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kja7xLJY54zE"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "# from keras.applications import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "from PIL import Image\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import tensorflow as tf\n",
    "from keras.regularizers import Regularizer\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from scipy.misc import imsave\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZymTXUqh54zH"
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aPXtk2qm54zK"
   },
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KejCZ0m154zK"
   },
   "outputs": [],
   "source": [
    "#https://github.com/misgod/fast-neural-style-keras/blob/master/VGG16.py\n",
    "\"\"\"VGG16 model for Keras.\n",
    "# Reference\n",
    "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D, GlobalAveragePooling2D,GlobalMaxPooling2D\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.applications.imagenet_utils import decode_predictions, preprocess_input\n",
    "from keras_applications.imagenet_utils import _obtain_input_shape\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "\n",
    "def VGG16(include_top=True, weights='imagenet',\n",
    "          input_tensor=None, input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000):\n",
    "    \"\"\"Instantiates the VGG16 architecture.\n",
    "    Optionally loads weights pre-trained\n",
    "    on ImageNet. Note that when using TensorFlow,\n",
    "    for best performance you should set\n",
    "    `image_data_format=\"channels_last\"` in your Keras config\n",
    "    at ~/.keras/keras.json.\n",
    "    The model and the weights are compatible with both\n",
    "    TensorFlow and Theano. The data format\n",
    "    convention used by the model is the one\n",
    "    specified in your Keras config file.\n",
    "    # Arguments\n",
    "        include_top: whether to include the 3 fully-connected\n",
    "            layers at the top of the network.\n",
    "        weights: one of `None` (random initialization)\n",
    "            or \"imagenet\" (pre-training on ImageNet).\n",
    "        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 244)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels,\n",
    "            and width and height should be no smaller than 48.\n",
    "            E.g. `(200, 200, 3)` would be one valid value.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    if weights not in {'imagenet', None}:\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization) or `imagenet` '\n",
    "                         '(pre-training on ImageNet).')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as imagenet with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      require_flatten=include_top)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = Flatten(name='flatten')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc1')(x)\n",
    "        x = Dense(4096, activation='relu', name='fc2')(x)\n",
    "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # load weights\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                                    WEIGHTS_PATH,\n",
    "                                    cache_subdir='models')\n",
    "        else:\n",
    "            weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                                    WEIGHTS_PATH_NO_TOP,\n",
    "                                    cache_subdir='models')\n",
    "        model.load_weights(weights_path,by_name=True)\n",
    "        if K.backend() == 'theano':\n",
    "            layer_utils.convert_all_kernels_in_model(model)\n",
    "\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            if include_top:\n",
    "                maxpool = model.get_layer(name='block5_pool')\n",
    "                shape = maxpool.output_shape[1:]\n",
    "                dense = model.get_layer(name='fc1')\n",
    "                layer_utils.convert_dense_weights_data_format(dense, shape, 'channels_first')\n",
    "\n",
    "            if K.backend() == 'tensorflow':\n",
    "                warnings.warn('You are using the TensorFlow backend, yet you '\n",
    "                              'are using the Theano '\n",
    "                              'image data format convention '\n",
    "                              '(`image_data_format=\"channels_first\"`). '\n",
    "                              'For best performance, set '\n",
    "                              '`image_data_format=\"channels_last\"` in '\n",
    "                              'your Keras config '\n",
    "                              'at ~/.keras/keras.json.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LnEwhRRu54zM"
   },
   "source": [
    "# Loss Regularizations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mJS2mXAz54zN"
   },
   "outputs": [],
   "source": [
    "def gram_matrix(F):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        F: response of a layler L\n",
    "    output:\n",
    "        gram matrix of F\n",
    "    \"\"\"\n",
    "    shape = K.shape(F)\n",
    "    chw = K.cast(shape[0]*shape[1]*shape[2],dtype='float32')\n",
    "    F_new = K.reshape(F,(shape[0]*shape[1],shape[2]))\n",
    "    F_t = K.transpose(F_new)\n",
    "    return K.dot(F_t,F_new)/chw\n",
    "\n",
    "class Total_variation(Regularizer):\n",
    "    def __init__(self, weight=2e2):\n",
    "        self.weight= weight\n",
    "        super(Total_variation, self).__init__()\n",
    "    def __call__(self,x):\n",
    "        predict = x.output #image after normalize\n",
    "        a = K.square(predict[:,:255,:255,:]-predict[:,1:,:255,:])\n",
    "        b = K.square(predict[:,:255,:255,:]-predict[:,255:,:1,:])\n",
    "        loss = self.weight*K.sum(K.pow(a+b,1.25))\n",
    "        return loss\n",
    "        \n",
    "class layer_content_loss(Regularizer):\n",
    "    def __init__(self, weight=2e2):\n",
    "        super(layer_content_loss, self).__init__()\n",
    "        self.weight= weight\n",
    "    def __call__(self,x):\n",
    "        images = x.output #image after normalize\n",
    "        content = images[1]\n",
    "        pred = images[0]\n",
    "        shape = K.int_shape(pred)\n",
    "#         chw = 1/(shape[0]*shape[1]*shape[2])\n",
    "        return K.sum(K.mean(K.square(content-pred)))*self.weight      \n",
    "    \n",
    "class layer_style_loss(Regularizer):\n",
    "    def __init__(self, weight=2e2):\n",
    "        self.weight= weight\n",
    "        super(layer_style_loss, self).__init__()\n",
    "    def __call__(self,x):\n",
    "        images = x.output #image after normalize\n",
    "        style = gram_matrix(images[2])\n",
    "        pred = gram_matrix(images[0])\n",
    "        return K.sum(K.square(style-pred))*self.weight   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XBJWl2fr54zP"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6M05p3CT54zQ"
   },
   "source": [
    "## image transformation supplement functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k-2nH_7I54zR"
   },
   "outputs": [],
   "source": [
    "#residual block \n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "def load_image(path):\n",
    "    img = load_img(path,target_size=(256,256,3))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img.astype('float32')\n",
    "    return img\n",
    "        \n",
    "\n",
    "def display_img(i,x,style,is_val=False):\n",
    "    # save current generated image\n",
    "    img = x \n",
    "    if is_val:\n",
    "        fname = '%s_%d_val.png' % (style,i)\n",
    "    else:\n",
    "        fname = '%s_%d.png' % (style,i)\n",
    "    imsave(fname, img)\n",
    "    print('Image saved as', fname)\n",
    "\n",
    "\n",
    "#Normalize input image\n",
    "\n",
    "class InputNormalize(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(InputNormalize, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        return x/255.\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "\n",
    "class InputNormalizeLossNet(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(InputNormalizeLossNet, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        x = x[:, :, :, ::-1]       \n",
    "        x -= 120\n",
    "        return x\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return input_shape\n",
    "\n",
    "\n",
    "class InputDenormalize(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(InputDenormalize, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        pass\n",
    "\n",
    "    def call(self, x):\n",
    "        return x*150+255/2\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zt0jsR1M54zT"
   },
   "source": [
    "## Image transform model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vENYW5dT54zU"
   },
   "outputs": [],
   "source": [
    "def residual_block(x, num):\n",
    "    shortcut = x\n",
    "    x = layers.Conv2D(128, (3, 3), strides=1, padding='same', name='resi_conv_%d_1' % num)(x)\n",
    "    x = layers.BatchNormalization(name='resi_normal_%d_1' % num)(x)\n",
    "    x = layers.Activation('relu', name='resi_relu_%d_1' % num)(x)\n",
    "    x = layers.Conv2D(128, (3, 3), strides=1, padding='same', name='resi_conv_%d_2' % num)(x)\n",
    "    x = layers.BatchNormalization(name='resi_normal_%d_2' % num)(x)\n",
    "    m = layers.add([x, shortcut], name='resi_add_%d' % num)\n",
    "    return m\n",
    "\n",
    "\n",
    "def Convolution_block(x,filters,kernel_size,stride,i,activation):\n",
    "    x = layers.Conv2D(filters,kernel_size, strides=stride, padding='same', name='conv_'+str(i))(x)\n",
    "    x = layers.BatchNormalization(name='normal_%d' % i)(x)\n",
    "    x = layers.Activation(activation, name='%s_%d' % (activation,i))(x)\n",
    "    return x\n",
    "\n",
    "def Convolution_block_T(x,filters,kernel_size,stride,i,activation):\n",
    "    x = layers.Conv2DTranspose(filters,kernel_size, strides=stride, padding='same', name='conv_'+str(i))(x)\n",
    "    x = layers.BatchNormalization(name='normal_%d' % i)(x)\n",
    "    x = layers.Activation(activation, name='%s_%d' % (activation,i))(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def image_transform_model(vari_weight):\n",
    "    image_size = (256,256,3)\n",
    "    #Image transformation network\n",
    "    input_origin = layers.Input(shape=image_size,name=\"input_origin\")\n",
    "    #normalize image \n",
    "    norm_input = InputNormalize()(input_origin)\n",
    "    \n",
    "    #the network\n",
    "    \n",
    "    c1 = Convolution_block(x= norm_input,\n",
    "                           filters= 32,\n",
    "                           kernel_size =(9,9),\n",
    "                           stride = (1,1),\n",
    "                           i=1,\n",
    "                           activation='relu')\n",
    "\n",
    "    c2 = Convolution_block(x= c1,\n",
    "                           filters= 64,\n",
    "                           kernel_size =(3,3),\n",
    "                           stride = (2,2),\n",
    "                           i=2,\n",
    "                           activation='relu')\n",
    "\n",
    "    c3 = Convolution_block(x= c2,\n",
    "                           filters= 128,\n",
    "                           kernel_size =(3,3),\n",
    "                           stride = (2,2),\n",
    "                           i=3,\n",
    "                           activation='relu')\n",
    "\n",
    "    r1 = residual_block(c3, 1)\n",
    "    r2 = residual_block(r1, 2)\n",
    "    r3 = residual_block(r2, 3)\n",
    "    r4 = residual_block(r3, 4)\n",
    "    r5 = residual_block(r4, 5)\n",
    "\n",
    "    d1 = Convolution_block_T(x= r5,\n",
    "                           filters= 64,\n",
    "                           kernel_size =(3,3),\n",
    "                           stride = (2,2),\n",
    "                           i=4,\n",
    "                           activation='relu')\n",
    "    d2 = Convolution_block_T(x= d1,\n",
    "                           filters= 32,\n",
    "                           kernel_size =(3,3),\n",
    "                           stride = (2,2),\n",
    "                           i=5,\n",
    "                           activation='relu')\n",
    "\n",
    "    c4 = Convolution_block(x= d2,\n",
    "                           filters= 3,\n",
    "                           kernel_size =(9,9),\n",
    "                           stride = (1,1),\n",
    "                           i=6,\n",
    "                           activation='tanh')\n",
    "    \n",
    "    output= InputDenormalize()(c4)\n",
    "#Need to have denormalize layer at the last one because we need the full\n",
    "#unormalized image before putting it back VGG16\n",
    "    model = Model([input_origin],[output])\n",
    "    \n",
    "    vari_loss = Total_variation(vari_weight)(model.layers[-1])\n",
    "    (model.layers[-1]).add_loss(vari_loss)\n",
    "    \"\"\"\n",
    "    add Total variation regularizer\n",
    "    We use regularizer because in our final model design for each loss because\n",
    "    for each of the designated layer in our total network, we will have \n",
    "    one loss (total variation loss in this case) and we want to cooperate it\n",
    "    into the final model's loss. \n",
    "    \"\"\"\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rMdrDnAv54zW"
   },
   "source": [
    "## Dummy style network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7SI27O-54zW"
   },
   "outputs": [],
   "source": [
    "def style_network():\n",
    "    inp = layers.Input((256, 256, 3),name=\"DUMMY\")\n",
    "    out = layers.Lambda(lambda x: x)(inp)\n",
    "    model = Model(inp, out)\n",
    "    return model \n",
    "\n",
    "\n",
    "def dummy_loss(y_true, y_pred ):\n",
    "    return K.variable(0.0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4zsr_9AM54zZ"
   },
   "source": [
    "## Loss network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VTQnWNJV54zZ"
   },
   "outputs": [],
   "source": [
    "def loss_network(x_trans,x_input,style_input,content_weight,style_weight):\n",
    "    \"\"\"Append initial input with the output of the image transform \n",
    "    network because we will the intial input as the content input.\n",
    "    \"\"\"\n",
    "#     style_matrix = K.constant(style)\n",
    "#     style_matrix= preprocess_input(style_matrix)\n",
    "#     x_trans= preprocess_input(x_trans)\n",
    "#     x_input = preprocess_input(x_input)\n",
    "#     x = concatenate([x_trans,x_input,style_matrix], axis=0)\n",
    "\n",
    "    x = concatenate([x_trans,x_input,style_input], axis=0)\n",
    "    input_origin = layers.Input(shape=image_size,name=\"input_origin\")\n",
    "    \n",
    "    x = InputNormalizeLossNet()(x)\n",
    "\n",
    "\n",
    "    model = VGG16(input_tensor=x, include_top=False)\n",
    "    out_layers = {layer.name: layer for layer in model.layers[-18:]}\n",
    "\n",
    "    #style loss\n",
    "    STYLE_LAYER = ['block1_conv2', 'block2_conv2', 'block3_conv3', 'block4_conv3']\n",
    "    \n",
    "    for layer_name in STYLE_LAYER:\n",
    "        layer = out_layers[layer_name]\n",
    "        style_loss = layer_style_loss(style_weight)(layer)\n",
    "        layer.add_loss(style_loss)\n",
    "\n",
    "\n",
    "    #content loss \n",
    "    CONTENT_LAYER = 'block3_conv3'\n",
    "    content_layer = out_layers[CONTENT_LAYER]\n",
    "    content_loss = layer_content_loss(content_weight)(content_layer)\n",
    "    content_layer.add_loss(content_loss)\n",
    "\n",
    "    for lay in model.layers[-19:]:\n",
    "        lay.trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2-QqlSFk54zb"
   },
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put the path to style and desired content image here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "style = load_image(\"../data/style/son_dau.jpg\")\n",
    "img = load_image(\"../data/content/bird.jpg\") #test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onyO9adH54zc"
   },
   "outputs": [],
   "source": [
    "image_size = (256,256,3)\n",
    "\n",
    "\n",
    "content_weight = 1\n",
    "style_weight = 4\n",
    "transform_model =  image_transform_model(1e-3)\n",
    "style_network = style_network() \n",
    "loss_network = loss_network(transform_model.output,transform_model.input\n",
    "                            ,style_network.input,\n",
    "                            content_weight,style_weight)\n",
    "dummy_y = np.zeros((1,256,256,3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBFyVkyD54ze"
   },
   "source": [
    "## Fit with real train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jy1jKUWN54zf"
   },
   "outputs": [],
   "source": [
    "adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "\n",
    "loss_network.compile(optimizer = adam,loss=dummy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2703
    },
    "colab_type": "code",
    "id": "1tbUFjWy54zg",
    "outputId": "129f4feb-edc1-4aa1-847a-f412eba6210d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_origin (InputLayer)       (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_normalize_1 (InputNormali (None, 256, 256, 3)  0           input_origin[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 256, 256, 32) 7808        input_normalize_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "normal_1 (BatchNormalization)   (None, 256, 256, 32) 128         conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_1 (Activation)             (None, 256, 256, 32) 0           normal_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Conv2D)                 (None, 128, 128, 64) 18496       relu_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "normal_2 (BatchNormalization)   (None, 128, 128, 64) 256         conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_2 (Activation)             (None, 128, 128, 64) 0           normal_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 64, 64, 128)  73856       relu_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "normal_3 (BatchNormalization)   (None, 64, 64, 128)  512         conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_3 (Activation)             (None, 64, 64, 128)  0           normal_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_1_1 (Conv2D)          (None, 64, 64, 128)  147584      relu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_1_1 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_1_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_relu_1_1 (Activation)      (None, 64, 64, 128)  0           resi_normal_1_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_1_2 (Conv2D)          (None, 64, 64, 128)  147584      resi_relu_1_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_1_2 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_1_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_add_1 (Add)                (None, 64, 64, 128)  0           resi_normal_1_2[0][0]            \n",
      "                                                                 relu_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_2_1 (Conv2D)          (None, 64, 64, 128)  147584      resi_add_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_2_1 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_2_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_relu_2_1 (Activation)      (None, 64, 64, 128)  0           resi_normal_2_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_2_2 (Conv2D)          (None, 64, 64, 128)  147584      resi_relu_2_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_2_2 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_2_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_add_2 (Add)                (None, 64, 64, 128)  0           resi_normal_2_2[0][0]            \n",
      "                                                                 resi_add_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_3_1 (Conv2D)          (None, 64, 64, 128)  147584      resi_add_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_3_1 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_3_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_relu_3_1 (Activation)      (None, 64, 64, 128)  0           resi_normal_3_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_3_2 (Conv2D)          (None, 64, 64, 128)  147584      resi_relu_3_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_3_2 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_3_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_add_3 (Add)                (None, 64, 64, 128)  0           resi_normal_3_2[0][0]            \n",
      "                                                                 resi_add_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_4_1 (Conv2D)          (None, 64, 64, 128)  147584      resi_add_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_4_1 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_4_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_relu_4_1 (Activation)      (None, 64, 64, 128)  0           resi_normal_4_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_4_2 (Conv2D)          (None, 64, 64, 128)  147584      resi_relu_4_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_4_2 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_4_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_add_4 (Add)                (None, 64, 64, 128)  0           resi_normal_4_2[0][0]            \n",
      "                                                                 resi_add_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_5_1 (Conv2D)          (None, 64, 64, 128)  147584      resi_add_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_5_1 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_5_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_relu_5_1 (Activation)      (None, 64, 64, 128)  0           resi_normal_5_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "resi_conv_5_2 (Conv2D)          (None, 64, 64, 128)  147584      resi_relu_5_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_normal_5_2 (BatchNormaliza (None, 64, 64, 128)  512         resi_conv_5_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "resi_add_5 (Add)                (None, 64, 64, 128)  0           resi_normal_5_2[0][0]            \n",
      "                                                                 resi_add_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Conv2DTranspose)        (None, 128, 128, 64) 73792       resi_add_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "normal_4 (BatchNormalization)   (None, 128, 128, 64) 256         conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_4 (Activation)             (None, 128, 128, 64) 0           normal_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Conv2DTranspose)        (None, 256, 256, 32) 18464       relu_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "normal_5 (BatchNormalization)   (None, 256, 256, 32) 128         conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu_5 (Activation)             (None, 256, 256, 32) 0           normal_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_6 (Conv2D)                 (None, 256, 256, 3)  7779        relu_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "normal_6 (BatchNormalization)   (None, 256, 256, 3)  12          conv_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tanh_6 (Activation)             (None, 256, 256, 3)  0           normal_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_denormalize_1 (InputDenor (None, 256, 256, 3)  0           tanh_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "DUMMY (InputLayer)              (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256, 256, 3)  0           input_denormalize_1[0][0]        \n",
      "                                                                 input_origin[0][0]               \n",
      "                                                                 DUMMY[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "input_normalize_loss_net_1 (Inp (None, 256, 256, 3)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 256, 256, 64) 1792        input_normalize_loss_net_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 256, 256, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 128, 128, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 128, 128, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 128, 128, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 64, 64, 128)  0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 64, 64, 256)  295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 64, 64, 256)  590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 32, 32, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 32, 32, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 32, 32, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 16, 16, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 16, 16, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 16, 16, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 8, 8, 512)    0           block5_conv3[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 16,397,135\n",
      "Trainable params: 1,679,241\n",
      "Non-trainable params: 14,717,894\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loss_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xlZ5bgso54zi",
    "outputId": "94e03224-73d6-4879-ab78-baab9e1f4fba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81434/81434 [00:00<00:00, 1420020.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "file_count = 0\n",
    "content_imgs = None\n",
    "paths = []\n",
    "for filename in tqdm(os.listdir('test2015')):\n",
    "    path = 'test2015/' + filename\n",
    "    paths.append(path)\n",
    "    file_count += 1\n",
    "#     if file_count >= 10:\n",
    "#         break\n",
    "        \n",
    "def gen_img(paths,style): \n",
    "    while True: \n",
    "        for path in paths:\n",
    "            image = load_image(path)\n",
    "            features = image.copy()\n",
    "            label = image.copy()\n",
    "            yield ([features,style], dummy_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "p1O_NEgj54zk",
    "outputId": "8cef745c-d095-4237-cce5-9659bac58337"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "81000/81000 [==============================] - 8014s 99ms/step - loss: 346950678.0484\n",
      "Epoch 2/2\n",
      "31710/81000 [==========>...................] - ETA: 1:21:18 - loss: 279602913.7050"
     ]
    }
   ],
   "source": [
    "loss_network.fit_generator(generator=gen_img(paths,style), steps_per_epoch=81000,epochs=2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9N4hWERn54zl"
   },
   "outputs": [],
   "source": [
    "Image.fromarray(transform_model.predict(img)[0].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwblhTxM54zo"
   },
   "outputs": [],
   "source": [
    "img = load_image(\"/data/ttran/val2017/000000084170.jpg\")\n",
    "display_img(2,transform_model.predict(img)[0], \"starry night\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Fast-Neural-Style Model.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
